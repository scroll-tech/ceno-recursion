\section{The Case for a New SNARK Framework}
The goal of \CoBBl~is to explore a middle path between compiler-style and VM-style SNARKs. To achieve so, it takes inspirations from two existing systems from the two approaches: CirC and vRAM. To illustrate the design of \CoBBl, we first provide brief descriptions of our two predecessors.

\subsection{CirC}
CirC is a compiler infrastructure that provides a link between high-level programming languages and arithmetic or logical circuits like R1CS or SMT. To achieve so, CirC translates a program of a high-level language into a state-free, non-uniform intermediate representation (IR) called CirC-IR. In the context of verifiable computation, these IRs are then lowered into R1CS in a standardized process in-line with those introduced by earlier works \cite{setty12ginger, wahby14buffet, kosba18xjsnark}. Additional optimizations like linear-reductions are deployed to minimize the size of the R1CS constraints.

We build the frontend of \CoBBl~largely based on CirC. In particular, \CoBBl~utilizes CirC's translation to and from CirC-IR for its own constraint generation. However, unlike CirC, which translates a flattened version of the entire program into IR, \CoBBl~invokes additional preprocessing that divides the program into segments, before converting individual segments into IR and R1CS.

\subsection{vRAM}
vRAM is a VC system with a circuit-independent preprocessing stage. This means that vRAM does not require any compile-time setup on the program to be verified. Instead, vRAM only requires a one-time setup that generates constraints for every TinyRAM instruction type. For proofs, $\P$ expresses any execution of any program as an \emph{execution trace}: a sequence of program states $[S_0\dots S_T]$, where the first state $S_0$ is the program input, and all subsequent states $S_{i+1}$ are generated by applying a TinyRAM instruction $I_i$ to the previous program state $S_i$. To verify the correctness of the trace, $\V$ checks the following:
\begin{itemize}
    \item All instructions are fetched correctly.
    \item All instructions are executed correctly.
    \item All memory accesses are coherent.
\end{itemize}

In order to achieve sublinear verification time, vRAM uses data-parallelism to generate a batched proof on all instructions. In concrete terms, it invokes the following procedures:
\begin{enumerate}
    \item For every state $S_i$ and instruction $I_i$, $\P$ appends the output of the instruction, $O_i$, to the end of $S_i$. The pair $(S_i, O_i)$ form the witnesses for verifying the correct execution of $I_i$.
    \item For every consecutive pair of program states $(S_i, O_i, S_{i+1})$, $\P$ proves that the corresponding register in $S_{i+1}$ is updated to $O_i$ and everything else stays the same.
    \item For instruction correctness, to minimize proof size, $\P$ first permutes the list of $(S_i, O_i)$ by the type of $I_i$, then verifies that $O_i$ is the correct output of applying $I_i$ on $S_i$. The permutation allows the proof to only include one copy of constraints for each type of instruction executed. We cover this process in more details in section \ref{sec:block_correctness}
    \item Finally, constraints of memory operations extract out all memory accesses. Through a separate permutation, $\P$ proves memory coherency in an approach first introduced by Buffet \cite{wahby14buffet}.
\end{enumerate}

The final proof of vRAM is consisted of four components:
\begin{enumerate}
    \item Pairwise program state consistency check.
    \item Permutation of $(S_i, O_i)$ from execution-order to instruction-order.
    \item Batched instruction correctness check.
    \item Memory coherence check.
\end{enumerate}

We apply this high-level idea of 4-component proof to the proving structure behind \CoBBl, with major changes in each component to match the output of the \CoBBl~frontend.

\subsection{Motivating for a new SNARK system}
While CirC and vRAM are highly efficient in their own regards, they also introduce different overheads in the process. The CirC compiler, as described briefly in the introduction, generates a flattened, static IR for the program. The constraints lowered from such IR need to account for all execution paths, which leads to two problems:
\begin{enumerate}
    \item The constraints need to express all branches of a conditional, even though only one would be taken in any execution. This creates "wastes" in the proof, \emph{i.e.} constraints that do not correspond to an executed instruction.
    \item All loops within the program needs to be flattened and unrolled. Such a process results in constraint size linear to the execution trace, as opposed to size of the code, inflating the work of the compiler and preprocessor. Further more, loops without an explicit upper bound on number of iterations require hints from the programmer for unrolling; if supplied incorrectly, can compromise proof completeness and soundness. 
\end{enumerate}

vRAM solves the above problems by verifying the execution trace and eliminating program-specific preprocessing. In order to do so, however, vRAM introduces program state consistency check. Every instruction $I_i$ in the execution trace translates to one additional $(S_i, O_i)$ entry in the program state permutation and one additional consistency check between $S_i$ and $S_{i+1}$. Both overheads require linear scan on the program state. For cheap instructions like addition and multiplication, verifying permutation and consistency can be more costly than the instruction itself.

%\red{Detailed runtime comparison?}